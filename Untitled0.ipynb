{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfZSiBOKsSem5XBCOGKrK3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtDowdy/deep-learning-engagement/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfvWe9LZ46R-"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Multimodal Content Understanding (PyTorch, Colab-ready)\n",
        "# Text (synopsis) + Tabular (genre, duration, maturity) -> Engagement Score\n",
        "# - BiGRU + Additive Attention for text\n",
        "# - MLP for tabular metadata\n",
        "# - Fusion head with dropout + layernorm\n",
        "# - AMP training, early stopping, cosine schedule\n",
        "# - Metrics: AUC, Accuracy, Brier Score, ECE (calibration), per-genre AUC\n",
        "# - Exports: TorchScript + ONNX for deployment\n",
        "# ============================================================\n",
        "\n",
        "import os, math, random, json, itertools\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "# ------------- Repro & Config -------------\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "seed_everything(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "CFG = {\n",
        "    \"max_vocab\": 8000,\n",
        "    \"max_len\": 64,\n",
        "    \"embed_dim\": 128,\n",
        "    \"rnn_hidden\": 128,\n",
        "    \"rnn_layers\": 1,\n",
        "    \"tab_hidden\": 64,\n",
        "    \"fusion_hidden\": 128,\n",
        "    \"dropout\": 0.2,\n",
        "    \"batch_size\": 128,\n",
        "    \"lr\": 2e-3,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"epochs\": 12,\n",
        "    \"early_patience\": 3,\n",
        "    \"train_val_split\": 0.85,\n",
        "}\n",
        "\n",
        "# ------------- Synthetic Data Generator -------------\n",
        "GENRES = [\"drama\", \"comedy\", \"thriller\", \"documentary\", \"action\", \"romance\", \"scifi\"]\n",
        "MATURITY = [\"G\", \"PG\", \"PG-13\", \"R\", \"TV-MA\"]\n",
        "\n",
        "sentiment_pos = [\"heartwarming\", \"uplifting\", \"award-winning\", \"beloved\", \"captivating\", \"hilarious\", \"feel-good\"]\n",
        "sentiment_neg = [\"grim\", \"bleak\", \"slow\", \"confusing\", \"derivative\", \"predictable\", \"gory\"]\n",
        "hooks = [\"edge-of-your-seat\", \"bingeable\", \"critically-acclaimed\", \"fan-favorite\", \"character-driven\"]\n",
        "topics = [\"family\", \"space\", \"heist\", \"chef\", \"music\", \"athlete\", \"detective\", \"robot\", \"time-travel\", \"politics\", \"school\"]\n",
        "\n",
        "def make_synopsis(genre, maturity, good=True):\n",
        "    tokens = []\n",
        "    tokens += [random.choice(topics) for _ in range(2)]\n",
        "    tokens += [random.choice(hooks)]\n",
        "    if good:\n",
        "        tokens += [random.choice(sentiment_pos) for _ in range(2)]\n",
        "    else:\n",
        "        tokens += [random.choice(sentiment_neg) for _ in range(2)]\n",
        "    fillers = [\"story\", \"journey\", \"friends\", \"discover\", \"secret\", \"mission\", \"season\", \"episode\", \"world\", \"small-town\"]\n",
        "    tokens += [random.choice(fillers) for _ in range(10)]\n",
        "    tokens += [genre, maturity.lower()]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "def simulate_dataset(N=5000):\n",
        "    rows = []\n",
        "    for _ in range(N):\n",
        "        genre = random.choice(GENRES)\n",
        "        maturity = random.choice(MATURITY)\n",
        "        duration = max(50, int(np.random.normal(105, 25)))  # minutes\n",
        "        base = 0.35\n",
        "        if genre in [\"comedy\",\"thriller\",\"documentary\"]: base += 0.1\n",
        "        if maturity in [\"PG-13\",\"TV-MA\"]: base += 0.05\n",
        "        if 85 <= duration <= 120: base += 0.05\n",
        "        good_text = random.random() < base\n",
        "        synopsis = make_synopsis(genre, maturity, good=good_text)\n",
        "        p = base + (0.10 if good_text else -0.05) + np.random.normal(0, 0.04)\n",
        "        p = float(np.clip(p, 0.02, 0.98))\n",
        "        y = int(random.random() < p)\n",
        "        rows.append({\"synopsis\": synopsis,\n",
        "                     \"genre\": genre,\n",
        "                     \"maturity\": maturity,\n",
        "                     \"duration\": duration,\n",
        "                     \"label\": y})\n",
        "    return rows\n",
        "\n",
        "data = simulate_dataset(5000)\n",
        "\n",
        "# ------------- Vocab / Tokenization -------------\n",
        "def tokenize(text: str) -> List[str]:\n",
        "    return [t.strip(\".,!?:;\\\"'()[]\").lower() for t in text.split() if t.strip()]\n",
        "\n",
        "all_tokens = list(itertools.chain.from_iterable(tokenize(r[\"synopsis\"]) for r in data))\n",
        "from collections import Counter\n",
        "freqs = Counter(all_tokens)\n",
        "itos = [\"<pad>\", \"<unk>\"] + [w for w,_ in freqs.most_common(CFG[\"max_vocab\"]-2)]\n",
        "stoi = {w:i for i,w in enumerate(itos)}\n",
        "\n",
        "def encode(text, max_len=CFG[\"max_len\"]):\n",
        "    toks = tokenize(text)\n",
        "    ids = [stoi.get(t, 1) for t in toks][:max_len]\n",
        "    if len(ids) < max_len:\n",
        "        ids += [0]*(max_len - len(ids))\n",
        "    return np.int64(ids)\n",
        "\n",
        "# ------------- Categorical Encoders -------------\n",
        "genre2ix = {g:i for i,g in enumerate(GENRES)}\n",
        "mat2ix = {m:i for i,m in enumerate(MATURITY)}\n",
        "\n",
        "def one_hot(idx, num):\n",
        "    v = np.zeros(num, dtype=np.float32)\n",
        "    v[idx] = 1.0\n",
        "    return v\n",
        "\n",
        "# ------------- Dataset / Dataloaders -------------\n",
        "class ContentDS(Dataset):\n",
        "    def __init__(self, rows):\n",
        "        self.rows = rows\n",
        "    def __len__(self): return len(self.rows)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.rows[i]\n",
        "        x_txt = encode(r[\"synopsis\"])\n",
        "        g_ix = genre2ix[r[\"genre\"]]\n",
        "        x_tab = np.concatenate([\n",
        "            one_hot(g_ix, len(GENRES)),\n",
        "            one_hot(mat2ix[r[\"maturity\"]], len(MATURITY)),\n",
        "            np.array([r[\"duration\"]], dtype=np.float32)/180.0\n",
        "        ]).astype(np.float32)\n",
        "        y = np.float32(r[\"label\"])\n",
        "        return torch.from_numpy(x_txt), torch.from_numpy(x_tab), torch.tensor(y), torch.tensor(g_ix, dtype=torch.long)\n",
        "\n",
        "ds = ContentDS(data)\n",
        "n_train = int(len(ds)*CFG[\"train_val_split\"])\n",
        "n_val = len(ds)-n_train\n",
        "train_ds, val_ds = random_split(ds, [n_train, n_val], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "# Colab tip: num_workers=0 is most portable in hosted envs\n",
        "train_loader = DataLoader(train_ds, batch_size=CFG[\"batch_size\"], shuffle=True, num_workers=0, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=CFG[\"batch_size\"], shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "# ------------- Model: TextEncoder (BiGRU + Additive Attention) -------------\n",
        "class AdditiveAttention(nn.Module):\n",
        "    def __init__(self, dim, hidden=64):\n",
        "        super().__init__()\n",
        "        self.W = nn.Linear(dim, hidden)\n",
        "        self.v = nn.Linear(hidden, 1, bias=False)\n",
        "    def forward(self, H, mask=None):\n",
        "        scores = self.v(torch.tanh(self.W(H))).squeeze(-1)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(~mask, -1e9)\n",
        "        w = torch.softmax(scores, dim=-1).unsqueeze(-1)\n",
        "        ctx = (H * w).sum(dim=1)\n",
        "        return ctx, w.squeeze(-1)\n",
        "\n",
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self, vocab, embed_dim, hidden, layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab, embed_dim, padding_idx=0)\n",
        "        self.rnn = nn.GRU(embed_dim, hidden, num_layers=layers, batch_first=True, bidirectional=True)\n",
        "        self.attn = AdditiveAttention(hidden*2, hidden)\n",
        "        self.norm = nn.LayerNorm(hidden*2)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "    def forward(self, x):\n",
        "        mask = x != 0\n",
        "        e = self.embed(x)\n",
        "        H,_ = self.rnn(e)\n",
        "        ctx,_ = self.attn(H, mask)\n",
        "        return self.drop(self.norm(ctx))\n",
        "\n",
        "# ------------- Tabular Encoder -------------\n",
        "class TabularEncoder(nn.Module):\n",
        "    def __init__(self, in_dim, hidden, dropout):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden, hidden),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.norm = nn.LayerNorm(hidden)\n",
        "    def forward(self, x):\n",
        "        return self.norm(self.net(x))\n",
        "\n",
        "# ------------- Fusion Head -------------\n",
        "class MultimodalCTR(nn.Module):\n",
        "    def __init__(self, vocab, text_dim, rnn_hidden, rnn_layers, tab_in, tab_hidden, fusion_hidden, dropout):\n",
        "        super().__init__()\n",
        "        self.txt = TextEncoder(vocab, text_dim, rnn_hidden, rnn_layers, dropout)\n",
        "        self.tab = TabularEncoder(tab_in, tab_hidden, dropout)\n",
        "        fused_in = rnn_hidden*2 + tab_hidden\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Linear(fused_in, fusion_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.LayerNorm(fusion_hidden),\n",
        "            nn.Linear(fusion_hidden, 1)\n",
        "        )\n",
        "    def forward(self, x_txt, x_tab):\n",
        "        h_txt = self.txt(x_txt)\n",
        "        h_tab = self.tab(x_tab)\n",
        "        z = torch.cat([h_txt, h_tab], dim=1)\n",
        "        logits = self.fuse(z).squeeze(1)\n",
        "        return logits\n",
        "\n",
        "tab_in_dim = len(GENRES) + len(MATURITY) + 1\n",
        "model = MultimodalCTR(\n",
        "    vocab=len(itos),\n",
        "    text_dim=CFG[\"embed_dim\"],\n",
        "    rnn_hidden=CFG[\"rnn_hidden\"],\n",
        "    rnn_layers=CFG[\"rnn_layers\"],\n",
        "    tab_in=tab_in_dim,\n",
        "    tab_hidden=CFG[\"tab_hidden\"],\n",
        "    fusion_hidden=CFG[\"fusion_hidden\"],\n",
        "    dropout=CFG[\"dropout\"]\n",
        ").to(device)\n",
        "\n",
        "# ------------- Optim, Schedule, Early Stop -------------\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=CFG[\"epochs\"])\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def brier_score(probs, targets):\n",
        "    probs = np.clip(probs, 1e-6, 1-1e-6)\n",
        "    return float(np.mean((probs - targets)**2))\n",
        "\n",
        "def ece_score(probs, targets, bins=10):\n",
        "    edges = np.linspace(0,1,bins+1)\n",
        "    ece = 0.0\n",
        "    for i in range(bins):\n",
        "        lo, hi = edges[i], edges[i+1]\n",
        "        m = (probs >= lo) & (probs < hi)\n",
        "        if m.any():\n",
        "            conf = probs[m].mean()\n",
        "            acc  = (targets[m] == (probs[m] >= 0.5)).mean()\n",
        "            ece += (m.mean()) * abs(conf - acc)\n",
        "    return float(ece)\n",
        "\n",
        "# ------------- Train Loop -------------\n",
        "best_val = float(\"inf\")\n",
        "best_state = None\n",
        "pat = 0\n",
        "\n",
        "for epoch in range(1, CFG[\"epochs\"]+1):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    for x_txt, x_tab, y, _gix in train_loader:\n",
        "        x_txt = x_txt.to(device); x_tab = x_tab.to(device); y = y.to(device)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "            logits = model(x_txt, x_tab)\n",
        "            loss = bce(logits, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "        running += loss.item() * x_txt.size(0)\n",
        "    scheduler.step()\n",
        "\n",
        "    # ---- Validation ----\n",
        "    model.eval()\n",
        "    vloss = 0.0\n",
        "    all_logits, all_y, all_gix = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for x_txt, x_tab, y, gix in val_loader:\n",
        "            x_txt = x_txt.to(device); x_tab = x_tab.to(device); y = y.to(device)\n",
        "            logits = model(x_txt, x_tab)\n",
        "            loss = bce(logits, y)\n",
        "            vloss += loss.item() * x_txt.size(0)\n",
        "            all_logits.append(logits.cpu()); all_y.append(y.cpu()); all_gix.append(gix.cpu())\n",
        "    vloss /= len(val_ds)\n",
        "    logits = torch.cat(all_logits).numpy()\n",
        "    targets = torch.cat(all_y).numpy()\n",
        "    gixs = torch.cat(all_gix).numpy()\n",
        "    probs = 1/(1+np.exp(-logits))\n",
        "    auc = roc_auc_score(targets, probs)\n",
        "    acc = accuracy_score(targets, probs>=0.5)\n",
        "    brier = brier_score(probs, targets)\n",
        "    ece = ece_score(probs, targets, bins=15)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | train_loss={running/len(train_ds):.4f} \"\n",
        "          f\"| val_loss={vloss:.4f} | AUC={auc:.3f} | ACC={acc:.3f} | Brier={brier:.3f} | ECE={ece:.3f}\")\n",
        "\n",
        "    # Early stopping on val_loss\n",
        "    if vloss < best_val - 1e-4:\n",
        "        best_val = vloss\n",
        "        best_state = {k: v.clone().cpu() for k,v in model.state_dict().items()}\n",
        "        pat = 0\n",
        "    else:\n",
        "        pat += 1\n",
        "        if pat >= CFG[\"early_patience\"]:\n",
        "            print(\"Early stopping.\")\n",
        "            break\n",
        "\n",
        "# Restore best\n",
        "if best_state is not None:\n",
        "    model.load_state_dict({k: v.to(device) for k,v in best_state.items()})\n",
        "\n",
        "# ------------- Per-Genre AUC (slice performance) -------------\n",
        "genre_auc = {}\n",
        "for gi, g in enumerate(GENRES):\n",
        "    m = gixs == gi\n",
        "    if m.sum() > 1 and len(np.unique(targets[m])) == 2:\n",
        "        genre_auc[g] = roc_auc_score(targets[m], probs[m])\n",
        "    else:\n",
        "        genre_auc[g] = float(\"nan\")\n",
        "\n",
        "print(\"\\nPer-genre AUC:\")\n",
        "for g,a in genre_auc.items():\n",
        "    print(f\"  {g:12s}: {a:.3f}\" if not math.isnan(a) else f\"  {g:12s}: n/a\")\n",
        "\n",
        "# ------------- Tiny “Quality Judge” (offline stand-in) -------------\n",
        "judge_good = set(sentiment_pos + hooks)\n",
        "judge_bad  = set(sentiment_neg)\n",
        "def quality_judge(texts: List[str]) -> np.ndarray:\n",
        "    scores = []\n",
        "    for t in texts:\n",
        "        toks = set(tokenize(t))\n",
        "        pos = len(toks & judge_good)\n",
        "        neg = len(toks & judge_bad)\n",
        "        score = (pos + 1) / (pos + neg + 2)  # Laplace-smooth\n",
        "        scores.append(score)\n",
        "    return np.array(scores, dtype=np.float32)\n",
        "\n",
        "sample_syn = [data[i][\"synopsis\"] for i in random.sample(range(len(data)), 256)]\n",
        "sample_enc = torch.tensor(np.stack([encode(s) for s in sample_syn])).to(device)\n",
        "avg_tab = torch.tensor(np.mean([np.concatenate([\n",
        "    one_hot(genre2ix[r[\"genre\"]], len(GENRES)),\n",
        "    one_hot(mat2ix[r[\"maturity\"]], len(MATURITY)),\n",
        "    np.array([r[\"duration\"]], dtype=np.float32)/180.0]) for r in data], axis=0), dtype=torch.float32)\n",
        "sample_tab = avg_tab.unsqueeze(0).repeat(len(sample_syn),1).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    p_probe = torch.sigmoid(model(sample_enc, sample_tab)).cpu().numpy()\n",
        "q_probe = quality_judge(sample_syn)\n",
        "corr = np.corrcoef(p_probe.flatten(), q_probe.flatten())[0,1]\n",
        "print(f\"\\nCorrelation(model_prob, quality_judge) ≈ {corr:.3f} (illustrative)\")\n",
        "\n",
        "# ------------- Inference Helper -------------\n",
        "def predict_example(synopsis: str, genre: str, maturity: str, duration_min: int):\n",
        "    x_txt = torch.tensor(encode(synopsis)).unsqueeze(0).to(device)\n",
        "    x_tab = torch.from_numpy(np.concatenate([\n",
        "        one_hot(genre2ix[genre], len(GENRES)),\n",
        "        one_hot(mat2ix[maturity], len(MATURITY)),\n",
        "        np.array([duration_min], dtype=np.float32)/180.0\n",
        "    ])).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        prob = torch.sigmoid(model(x_txt, x_tab)).item()\n",
        "    return prob\n",
        "\n",
        "demo_prob = predict_example(\n",
        "    synopsis=\"character-driven heist story with bingeable pacing and award-winning moments set in a small-town\",\n",
        "    genre=\"thriller\", maturity=\"PG-13\", duration_min=110\n",
        ")\n",
        "print(f\"\\nDemo inference prob (thriller, PG-13, 110m): {demo_prob:.3f}\")\n",
        "\n",
        "# ------------- Export: TorchScript + ONNX -------------\n",
        "model.eval()\n",
        "example_txt = torch.randint(0, len(itos), (1, CFG[\"max_len\"])).to(device)\n",
        "example_tab = torch.randn(1, tab_in_dim).to(device)\n",
        "\n",
        "# TorchScript\n",
        "scripted = torch.jit.trace(model, (example_txt, example_tab))\n",
        "os.makedirs(\"artifacts\", exist_ok=True)\n",
        "script_path = \"artifacts/multimodal_ctr_scripted.pt\"\n",
        "scripted.save(script_path)\n",
        "\n",
        "# ONNX\n",
        "onnx_path = \"artifacts/multimodal_ctr.onnx\"\n",
        "torch.onnx.export(\n",
        "    model, (example_txt, example_tab), onnx_path,\n",
        "    input_names=[\"synopsis_ids\", \"tabular_features\"],\n",
        "    output_names=[\"engagement_logit\"],\n",
        "    dynamic_axes={\"synopsis_ids\": {0:\"batch\"}, \"tabular_features\": {0:\"batch\"}, \"engagement_logit\": {0:\"batch\"}},\n",
        "    opset_version=13\n",
        ")\n",
        "print(f\"\\nSaved: {script_path} and {onnx_path}\")\n",
        "\n",
        "# ------------- Model Card (light) -------------\n",
        "def brier_score_np(p, t):  # reuse values computed earlier\n",
        "    p = np.clip(p, 1e-6, 1-1e-6); return float(np.mean((p - t)**2))\n",
        "\n",
        "card = {\n",
        "    \"task\": \"Engagement likelihood from synopsis + metadata\",\n",
        "    \"architecture\": \"BiGRU + AdditiveAttention (text) + MLP (tabular) with fusion\",\n",
        "    \"metrics\": {\n",
        "        \"val_loss\": round(float(best_val), 4),\n",
        "        \"AUC\": round(float(roc_auc_score(targets, probs)), 3),\n",
        "        \"ACC\": round(float(accuracy_score(targets, probs>=0.5)), 3),\n",
        "        \"Brier\": round(float(brier_score_np(probs, targets)), 3),\n",
        "        \"ECE\": round(float(ece_score(probs, targets, bins=15)), 3),\n",
        "        \"PerGenreAUC\": {k: (None if math.isnan(v) else round(float(v),3)) for k,v in genre_auc.items()}\n",
        "    },\n",
        "    \"export\": {\"torchscript\": script_path, \"onnx\": onnx_path},\n",
        "    \"notes\": [\n",
        "        \"Runs fully offline; synthetic data encodes realistic signals.\",\n",
        "        \"AMP enabled, cosine LR, early stopping; calibrated via ECE/Brier.\",\n",
        "        \"‘quality_judge’ shows how a judge model could be integrated; swap with a learned judge model in production.\"\n",
        "    ]\n",
        "}\n",
        "with open(\"artifacts/model_card.json\", \"w\") as f:\n",
        "    json.dump(card, f, indent=2)\n",
        "print(\"\\nModel card written to artifacts/model_card.json\")\n"
      ]
    }
  ]
}